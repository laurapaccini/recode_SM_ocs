{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_experiment import control_deaccu,fixedSM_deaccu\n",
    "import object_detection as obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "import tobac\n",
    "print(tobac.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable a few warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lon(ds,longitude='lon'):\n",
    "    ds.coords[longitude] = (ds.coords[longitude] + 180) % 360 - 180\n",
    "    ds = ds.sortby(ds.lon)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/scratch/wcq7pz/exp_levante_post/'\n",
    "## open topography, land_fraction\n",
    "topo5km = xr.open_dataset(path+'topography_dom03_5km.nc')\n",
    "topo5km.coords['lon'] = (topo5km.coords['lon'] + 180) % 360 - 180\n",
    "topo5km  = topo5km.sortby(topo5km.lon)\n",
    "\n",
    "## READ AMAZON MASK\n",
    "onlyab = xr.open_dataset('onlyab5km.nc')\n",
    "maskAB = onlyab.interp(lat = topo5km.lat,lon = topo5km.lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(array,xarr,time=True,varname='mask'):\n",
    "    if time==True:\n",
    "        ds = xr.Dataset( { varname: ([\"time\",\"lat\", \"lon\"], array)},\n",
    "    coords={ \"time\":([\"time\"],xarr.time.values), \"lat\": ([\"lat\"], xarr.lat.values),\"lon\": ([\"lon\"], \n",
    "             xarr.lon.values)})\n",
    "    else:\n",
    "        ds = xr.Dataset( { varname: ([\"lat\", \"lon\"], array)},\n",
    "    coords={ \"lat\": ([\"lat\"], xarr.lat.values),\"lon\": ([\"lon\"], xarr.lon.values)}) \n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_by_lifetime(Track,hours=3,operator='>'):\n",
    "    \"\"\"\n",
    "    for hourly data\n",
    "    \"\"\"\n",
    "    counts = Track.groupby(\"cell\")[\"time_cell\"].count().values\n",
    "    if operator == '<':\n",
    "        counts_min = Track.groupby(\"cell\")[\"time_cell\"].count()[counts<hours]\n",
    "    elif operator == '>':\n",
    "        counts_min = Track.groupby(\"cell\")[\"time_cell\"].count()[counts>hours]\n",
    "    else:\n",
    "        raise ValueError('Invalid operator. Choose either \"<\" or \">\".')\n",
    "    selected_cells = Track[Track[\"cell\"].isin(counts_min.reset_index()[counts_min.reset_index().cell>0].cell)]\n",
    "    selected_cells = selected_cells.reset_index()\n",
    "    #selected_cells = selected_cells.rename(columns={'lon': 'longitude'})\n",
    "    return selected_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subset_mask_new(df,ds_mask,var='labels_ocs',var2='mask_obs'):\n",
    "    # Filter the original dataset to only include times that are in the dataframe\n",
    "    original_ds_filtered = ds_mask.sel(time=df['time'].unique())\n",
    "    #new_mask = np.zeros_like(original_ds_filtered.labels_ocs);\n",
    "    \n",
    "    #create boolean\n",
    "    new_mask = [np.isin(original_ds_filtered.sel(time=i)[var],\n",
    "                        df[df.time==i].idxn.values) for i in original_ds_filtered.time.values] \n",
    "    \n",
    "    #make boolean a dataset\n",
    "    ds_new_mask = to_dataset(new_mask,original_ds_filtered)\n",
    "    \n",
    "    #apply to ds_filtered\n",
    "    new_ds = original_ds_filtered[var2].where(ds_new_mask.mask==True)\n",
    "        \n",
    "\n",
    "    return(new_ds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lon_attrs(ds):\n",
    "    ds.lon.attrs[\"standard_name\"] = \"longitude\"\n",
    "    ds.lon.attrs[\"long_name\"] = \"longitude\"\n",
    "    ds.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "    ds.lon.attrs[\"axis\"] = \"X\"\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_deaccu = update_lon_attrs(control_deaccu); \n",
    "fixedSM_deaccu = update_lon_attrs(fixedSM_deaccu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open objects (dataframes) and masks (3D datasets)\n",
    "## *************** Amazon region  ***************\n",
    "ds_ob_control_AB = xr.open_dataset('ds_ob_control5k_Amazon.nc') \n",
    "ds_ob_fixedSM_AB = xr.open_dataset('ds_ob_fixedSM5k_Amazon.nc')\n",
    "\n",
    "df_c_AB = pd.read_pickle('pkl_files/df_ob_control5k_Amazon.pkl') \n",
    "df_f_AB = pd.read_pickle('pkl_files/df_ob_fixedSM5k_Amazon.pkl') \n",
    "\n",
    "## *************** SESA region  ***************\n",
    "ds_ob_control_SESA = xr.open_dataset('ds_ob_control5k_SESA.nc') \n",
    "ds_ob_fixedSM_SESA = xr.open_dataset('ds_ob_fixedSM5k_SESA.nc')\n",
    "\n",
    "df_c_SESA = pd.read_pickle('pkl_files/df_ob_control5k_SESA.pkl') \n",
    "df_f_SESA = pd.read_pickle('pkl_files/df_ob_fixedSM5k_SESA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns to prepare for TOBAC tracking\n",
    "\n",
    "## *************** Amazon region  ***************\n",
    "df_c_AB = df_c_AB.reset_index(drop=True).reset_index().rename(columns={'index': 'feature'})\n",
    "df_c_AB['feature'] += 1 # Add 1 to the values in the \"feature\" column\n",
    "df_c_AB = df_c_AB.rename(columns={\"y\": \"hdim_1\", \"x\": \"hdim_2\"})\n",
    "\n",
    "df_f_AB = df_f_AB.reset_index(drop=True).reset_index().rename(columns={'index': 'feature'})\n",
    "df_f_AB['feature'] += 1\n",
    "df_f_AB = df_f_AB.rename(columns={\"y\": \"hdim_1\", \"x\": \"hdim_2\"})\n",
    "\n",
    "## *************** SESA region  ***************\n",
    "df_c_SESA = df_c_SESA.reset_index(drop=True).reset_index().rename(columns={'index': 'feature'})\n",
    "df_c_SESA['feature'] += 1\n",
    "df_c_SESA = df_c_SESA.rename(columns={\"y\": \"hdim_1\", \"x\": \"hdim_2\"})\n",
    "\n",
    "df_f_SESA = df_f_SESA.reset_index(drop=True).reset_index().rename(columns={'index': 'feature'})\n",
    "df_f_SESA['feature'] += 1\n",
    "df_f_SESA = df_f_SESA.rename(columns={\"y\": \"hdim_1\", \"x\": \"hdim_2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the \"frame\" column by grouping the data by unique values of \"time\"\n",
    "df_c_AB['frame'] = df_c_AB.groupby('time').ngroup()\n",
    "df_f_AB['frame'] = df_f_AB.groupby('time').ngroup()\n",
    "\n",
    "df_c_SESA['frame'] = df_c_SESA.groupby('time').ngroup()\n",
    "df_f_SESA['frame'] = df_f_SESA.groupby('time').ngroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid spacing of the input data (in meter)\n",
    "dxy = 4950 #(5km)\n",
    "dt = 3600 #200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing keyword arguments for the linking step:\n",
    "parameters_linking={}\n",
    "parameters_linking['method_linking']='predict'\n",
    "parameters_linking['adaptive_stop']=0.2\n",
    "parameters_linking['adaptive_step']=0.95\n",
    "parameters_linking['subnetwork_size']=100\n",
    "parameters_linking['memory']=0\n",
    "parameters_linking['time_cell_min']=5*60\n",
    "parameters_linking['v_max']=10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 847: 4 trajectories present.\n"
     ]
    }
   ],
   "source": [
    "Track_c_AB = tobac.linking_trackpy(df_c_AB,control_deaccu.tot_prec,dt=dt,dxy=dxy,**parameters_linking);\n",
    "Track_f_AB = tobac.linking_trackpy(df_f_AB,fixedSM_deaccu.tot_prec,dt=dt,dxy=dxy,**parameters_linking);\n",
    "\n",
    "Track_c_SESA = tobac.linking_trackpy(df_c_SESA,control_deaccu.tot_prec,dt=dt,dxy=dxy,**parameters_linking);\n",
    "Track_f_SESA = tobac.linking_trackpy(df_f_SESA,fixedSM_deaccu.tot_prec,dt=dt,dxy=dxy,**parameters_linking);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select objects with a lifetime larger than 3 hours\n",
    "sel_cells_c_AB = sel_by_lifetime(Track_c_AB);\n",
    "sel_cells_f_AB = sel_by_lifetime(Track_f_AB); \n",
    "\n",
    "sel_cells_c_SESA = sel_by_lifetime(Track_c_SESA);\n",
    "sel_cells_f_SESA = sel_by_lifetime(Track_f_SESA); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145 1072\n",
      "139 162\n"
     ]
    }
   ],
   "source": [
    "print(len(sel_cells_c_AB.cell.unique()),len(sel_cells_f_AB.cell.unique())) \n",
    "\n",
    "print(len(sel_cells_c_SESA.cell.unique()),len(sel_cells_f_SESA.cell.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare column 'idxn' to identify labels in the datasets (>3h)\n",
    "sel_cells_c_AB['idxn'] = (pd.to_numeric(sel_cells_c_AB['idx'],errors = 'coerce'))\n",
    "sel_cells_f_AB['idxn'] = (pd.to_numeric(sel_cells_f_AB['idx'],errors = 'coerce'))\n",
    "\n",
    "sel_cells_c_SESA['idxn'] = (pd.to_numeric(sel_cells_c_SESA['idx'],errors = 'coerce'))\n",
    "sel_cells_f_SESA['idxn'] = (pd.to_numeric(sel_cells_f_SESA['idx'],errors = 'coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new_mask of OCS (objects lasting > 3h)  \n",
    "nMask_c_AB = subset_mask_new(sel_cells_c_AB,ds_ob_control_AB)\n",
    "nMask_f_AB = subset_mask_new(sel_cells_f_AB,ds_ob_fixedSM_AB)\n",
    "\n",
    "nMask_c_SESA = subset_mask_new(sel_cells_c_SESA,ds_ob_control_SESA)\n",
    "nMask_f_SESA = subset_mask_new(sel_cells_f_SESA,ds_ob_fixedSM_SESA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save mask of OCS (objects lasting > 3h)  \n",
    "nMask_c_AB.to_netcdf('nMask_control_ocs_AB.nc'); \n",
    "nMask_f_AB.to_netcdf('nMask_fixedSM_ocs_AB.nc')\n",
    "\n",
    "nMask_c_SESA.to_netcdf('nMask_control_ocs_SESA.nc'); \n",
    "nMask_f_SESA.to_netcdf('nMask_fixedSM_ocs_SESA.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add stage information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stage_convective_system(df_tracked):\n",
    "    \"\"\"\n",
    "    Two main stages are initial t_i and t_f correspondent to first and last timesteps. Intermediate stages\n",
    "    are denoted t_1, t_2,..,t_n\n",
    "    \"\"\"\n",
    "    df = df_tracked[['cell','time_cell']].copy()\n",
    "\n",
    "    # count the number of stages for each cell\n",
    "    n_stages = df.groupby('cell')['time_cell'].count() - 1\n",
    "\n",
    "    # create a dictionary of stages for each cell\n",
    "    stages_dict = {}\n",
    "    for cell in n_stages.index:\n",
    "        if n_stages.loc[cell] == 2:\n",
    "            stages_dict[cell] = ['t_i'] + ['t_m'] + ['t_f']\n",
    "        elif (n_stages.loc[cell] > 2) and (n_stages.loc[cell] < 7):\n",
    "            stages_dict[cell] = ['t_i'] * 2 + ['t_m'] * (n_stages[cell]-3) + ['t_f'] * 2\n",
    "        \n",
    "        else:            \n",
    "            stages_dict[cell] = ['t_i'] * 3 + ['t_m'] * (n_stages[cell]-5) + ['t_f'] * 3\n",
    "\n",
    "    # create a new column 'stage' based on the cell and the stages dictionary\n",
    "    df['stage'] = [stages_dict[df.loc[i, 'cell']][df.groupby('cell').cumcount()[i]] for i in range(len(df))]\n",
    "    \n",
    "    dfn = df_tracked.reset_index(drop=True);\n",
    "    dfn['stage'] = df['stage']\n",
    "\n",
    "    return(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select objects with a lifetime larger than 3 hours\n",
    "df_stage_c_AB = add_stage_convective_system(sel_cells_c_AB)\n",
    "df_stage_f_AB = add_stage_convective_system(sel_cells_f_AB);\n",
    "\n",
    "df_stage_c_SESA = add_stage_convective_system(sel_cells_c_SESA)\n",
    "df_stage_f_SESA = add_stage_convective_system(sel_cells_f_SESA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stage_c_AB.to_pickle('pkl_files/df_stage_c_gt3h_AB.pkl');\n",
    "df_stage_f_AB.to_pickle('pkl_files/df_stage_f_gt3h_AB.pkl')\n",
    "\n",
    "df_stage_c_SESA.to_pickle('pkl_files/df_stage_c_gt3h_SESA.pkl');\n",
    "df_stage_f_SESA.to_pickle('pkl_files/df_stage_f_gt3h_SESA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_LP2",
   "language": "python",
   "name": "cloned_myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
